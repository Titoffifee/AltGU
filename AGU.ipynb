{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15G71RKyhlp-PxbIos9O4WLLTmSxUV67j",
      "authorship_tag": "ABX9TyPB+1y21z3MQs31cduKGtGJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Titoffifee/AltGU/blob/main/AGU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "!pip install pymorphy2"
      ],
      "metadata": {
        "id": "fQMQGkTohVJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfkLE6vmdHUl",
        "outputId": "0cc59d4c-1406-4bb7-cd2b-172c769e0a2c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "kR0TZo-fz8Mz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "workers = pd.read_csv('/content/drive/MyDrive/Владивосток/AltGU/employees.csv')\n",
        "train = pd.read_csv('/content/drive/MyDrive/Владивосток/train_dataset_train/train_issues.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Владивосток/test_dataset_test/test_issues.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop(['id', 'created', 'key', 'project_id'], axis=1)\n",
        "test = test.drop(['id', 'created', 'key', 'project_id'], axis=1)"
      ],
      "metadata": {
        "id": "7mHaEoSyVCNV"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = workers['id']\n",
        "workers['position'] = workers['position'].fillna('Web-разработчик')\n",
        "workers['payment_type'] = workers['payment_type'].fillna('fixed')\n",
        "test['summary'] = test['summary'].fillna('NAN')\n",
        "train['summary'] = train['summary'].fillna('NAN')\n",
        "d = workers[['active', 'position', 'payment_type']].to_dict()"
      ],
      "metadata": {
        "id": "yRu-x-G2cRYs"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy2\n",
        "import re\n",
        "\n",
        "patterns = \"[!#$%&'()*+,./:;<=>?@[\\]^_`{|}~—\\\"\\]+-0123456789\"\n",
        "table = dict()\n",
        "for el in patterns:\n",
        "  table[ord(el)] = ' '\n",
        "stopwords_ru = nltk.corpus.stopwords.words(\"russian\")\n",
        "stopwords_en = nltk.corpus.stopwords.words(\"english\")\n",
        "stop = stopwords_en + stopwords_ru\n",
        "\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "\n",
        "def lemmatize(doc):\n",
        "  doc = doc.translate(table)\n",
        "  print(doc)\n",
        "  tokens = []\n",
        "  for token in doc.split():\n",
        "    if token and token not in stop:\n",
        "      token = token.strip()\n",
        "      token = morph.normal_forms(token)[0]\n",
        "      \n",
        "      tokens.append(token)\n",
        "  return ' '.join(tokens)\n",
        "\n",
        "test['summary'] = test['summary'].apply(lemmatize)\n",
        "train['summary'] = train['summary'].apply(lemmatize)"
      ],
      "metadata": {
        "id": "vb7yfBMVeECv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_cnt = dict()\n",
        "for text in pd.concat([train['summary'], test['summary']]):\n",
        "  if type(text) == float:\n",
        "    continue\n",
        "  for token in text.split():\n",
        "    if token not in words_cnt:\n",
        "      words_cnt[token] = 0\n",
        "    words_cnt[token] += 1\n",
        "words_cnt = sorted(words_cnt.items(), key=lambda p: p[1])\n",
        "while words_cnt[0][1] == 1:\n",
        "  del words_cnt[0]\n",
        "words_cnt = set(map(lambda x: x[0], words_cnt))"
      ],
      "metadata": {
        "id": "YEQ7PBW1eMiC"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GetActive(ind):\n",
        "  if ind not in ids:\n",
        "    return 0 \n",
        "  return d['active'][ind]\n",
        "\n",
        "def GetPosition(ind):\n",
        "  if ind not in ids:\n",
        "    return 'Web-разработчик'\n",
        "  return d['position'][ind]\n",
        "\n",
        "def GetPayment(ind):\n",
        "  if ind not in ids:\n",
        "    return 'fixed'\n",
        "  return d['payment_type'][ind]\n",
        "\n",
        "def GetCorrectData(series):\n",
        "  active = series.apply(GetActive).rename('employee_active')\n",
        "  position = series.apply(GetPosition).rename('employee_position')\n",
        "  payment_type = series.apply(GetPayment).rename('employee_payment_type')\n",
        "  return pd.concat([active, position, payment_type], axis=1)\n",
        "\n",
        "X, y = train.drop(['overall_worklogs'], axis=1), train['overall_worklogs']\n",
        "\n",
        "X = pd.concat([X, GetCorrectData(X['assignee_id'])], axis=1)\n",
        "X = X.drop('creator_id', axis=1)"
      ],
      "metadata": {
        "id": "dGF1mnN9aI55"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = pd.concat([test, GetCorrectData(test['assignee_id'])], axis=1)\n",
        "X_test = X_test.drop(['creator_id'], axis=1)"
      ],
      "metadata": {
        "id": "RvNMkp6xBALO"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_X = pd.DataFrame(index=range(X.shape[0]), columns=list(words_cnt))\n",
        "summary_X_test = pd.DataFrame(index=range(X_test.shape[0]), columns=list(words_cnt))"
      ],
      "metadata": {
        "id": "_jP_uiCgfB3V"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind = 0\n",
        "for text in X['summary']:\n",
        "  if type(text) == float:\n",
        "    continue\n",
        "  for token in text.split():\n",
        "    if token in words_cnt:\n",
        "      summary_X.at[ind, token] = 1\n",
        "  ind += 1\n",
        "\n",
        "ind = 0\n",
        "for text in X_test['summary']:\n",
        "  if type(text) == float:\n",
        "    continue\n",
        "  for token in text.split():\n",
        "    if token in words_cnt:\n",
        "      summary_X_test.at[ind, token] = 1\n",
        "  ind += 1"
      ],
      "metadata": {
        "id": "wa-IL3fqfhFW"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_X = summary_X.fillna(0)\n",
        "summary_X_test = summary_X_test.fillna(0)"
      ],
      "metadata": {
        "id": "2gCPXoVrhsEZ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.concat([X.drop(['summary'], axis=1), summary_X], axis=1)\n",
        "X_test = pd.concat([X_test.drop(['summary'], axis=1), summary_X_test], axis=1)"
      ],
      "metadata": {
        "id": "qf0lipuzh2P7"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y /= 60"
      ],
      "metadata": {
        "id": "M5T8uR77iqK6"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj = ['employee_position', 'employee_payment_type', 'assignee_id']\n",
        "X = X.drop(obj + ['employee_active'], axis=1)\n",
        "X_test = X_test.drop(obj + ['employee_active'], axis=1)"
      ],
      "metadata": {
        "id": "AQKBZ3Pyryk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostRegressor\n",
        "\n",
        "model = CatBoostRegressor(silent=True, random_seed=0,\n",
        "                          depth=8, iterations=3200, learning_rate=0.04)\n",
        "# 6 100 0.01 - -0.01616"
      ],
      "metadata": {
        "id": "LTqEylsNirUW"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "result = cross_validate(model, X, y, cv=5, scoring='r2')"
      ],
      "metadata": {
        "id": "C4IMsezQJJqt"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['test_score'])\n",
        "print(result['test_score'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xel6kNaLXc1o",
        "outputId": "4c7a40fd-a563-4b71-9546-51a1d8b7c06c"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-6.95623732  0.30586933 -0.04512779 -3.56939026 -0.06207206]\n",
            "-2.065391621098176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y)\n",
        "result = model.predict(X_test)\n",
        "result *= 60\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyAgSF1qDnNr",
        "outputId": "c58adc1a-10c6-4fb7-f13b-541fdc882c23"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([16214.88230873, 16214.88230873, 16266.34257253, ...,\n",
              "       16245.8644799 , 16214.88230873, 16174.93262614])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[result <= 500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LYrzdqIcKQZ",
        "outputId": "de758fb9-9e6a-45f4-df9b-399cc1e47180"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], dtype=float64)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_result = pd.read_csv('/content/drive/MyDrive/Владивосток/AltGU/sample_solution.csv')\n",
        "df_result['overall_worklogs'] = result\n",
        "df_result.to_csv('/content/drive/MyDrive/Владивосток/ans.csv', index=False)\n",
        "df_result"
      ],
      "metadata": {
        "id": "LGmn_ELVCGkp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}